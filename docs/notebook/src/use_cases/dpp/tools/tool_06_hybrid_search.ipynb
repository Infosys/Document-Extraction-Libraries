{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ===============================================================================================================#\n",
                "# Copyright 2023 Infosys Ltd.                                                                          #\n",
                "# Use of this source code is governed by Apache License Version 2.0 that can be found in the LICENSE file or at  #\n",
                "# http://www.apache.org/licenses/                                                                                #\n",
                "# ===============================================================================================================#"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import json\n",
                "import shutil\n",
                "import infy_dpp_sdk\n",
                "import infy_fs_utils\n",
                "from IPython.display import display, HTML, Markdown\n",
                "from _internal_utils.pipeline_helper import PipelineHelper\n",
                "from _internal_utils.semantic_search_visualizer import SemanticSearchVisualizer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Set environment variables\n",
                "<div  style=\"line-height: 1;\">\n",
                "    <span style=\"color:Red\"><b>NOTE:</b> The Pipeline uses environment variables which needs to be set by the developer.<br>\n",
                "In production developer needs to set them as required.<br>\n",
                "In this notebook you can provide them using the below code.<br>\n",
                "To set or change the value please refer <i>installation.ipynb</i></span>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%store -r CUSTOM_LLM_BLOOM_INFERENCE_URL\n",
                "%store -r CUSTOM_LLM_LLAMA_INFERENCE_URL\n",
                "%store -r CUSTOM_LLM_MIXTRAL_INFERENCE_URL\n",
                "%store -r CUSTOM_LLM_LLAMA_3_1_INFERENCE_URL\n",
                "os.environ['CUSTOM_LLM_BLOOM_INFERENCE_URL']=CUSTOM_LLM_BLOOM_INFERENCE_URL\n",
                "os.environ['CUSTOM_LLM_LLAMA_INFERENCE_URL']=CUSTOM_LLM_LLAMA_INFERENCE_URL\n",
                "os.environ['CUSTOM_LLM_MIXTRAL_INFERENCE_URL']=CUSTOM_LLM_MIXTRAL_INFERENCE_URL\n",
                "os.environ['CUSTOM_LLM_LLAMA_3_1_INFERENCE_URL']=CUSTOM_LLM_LLAMA_3_1_INFERENCE_URL\n",
                "\n",
                "%store -r OPENAI_KEY\n",
                "os.environ['OPENAI_KEY'] = OPENAI_KEY\n",
                "%store -r OPENAI_SERVER_URL\n",
                "os.environ['OPENAI_SERVER_URL']=OPENAI_SERVER_URL\n",
                "\n",
                "%store -r CUSTOM_EMB_MISTRAL_INFERENCE_URL\n",
                "os.environ['CUSTOM_EMB_MISTRAL_INFERENCE_URL']=CUSTOM_EMB_MISTRAL_INFERENCE_URL"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Define configuration file path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "STORAGE_ROOT_PATH = 'C:/DPP/infy_libraries_client/STORAGE'\n",
                "CONTAINER_ROOT_PATH = 'C:/DPP/infy_libraries_client/CONTAINER'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Copying files\n",
                "<div style=\"line-height: 1;\">\n",
                "<span style=\"color:Red\"><b>NOTE: </b>In this notebook below is used to copy sample files to folders in <i>STORAGE_ROOT_PATH</i>.<br>\n",
                "In production the data and config files should be kept under respective folders in <i>STORAGE_ROOT_PATH </i>.<br>\n",
                "</span>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "curr_data = os.path.dirname(os.getcwd())+'/data'\n",
                "if not os.path.exists(f'{STORAGE_ROOT_PATH}/data'):\n",
                "    os.makedirs(f'{STORAGE_ROOT_PATH}/data')\n",
                "if not os.path.exists(f'{STORAGE_ROOT_PATH}/data/input'):\n",
                "    os.makedirs(f'{STORAGE_ROOT_PATH}/data/input')     \n",
                "shutil.copy(f'{curr_data}/sample/input/AR_2022-23_page-14-17.pdf',\n",
                "            f'{STORAGE_ROOT_PATH}/data/input/AR_2022-23_page-14-17.pdf')\n",
                "shutil.copytree(f'{curr_data}/sample/config',f'{STORAGE_ROOT_PATH}/data/config',\n",
                "                dirs_exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Initialize Client Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "storage_config_data = infy_fs_utils.data.StorageConfigData(\n",
                "        **{\n",
                "            \"storage_root_uri\": f\"file://{STORAGE_ROOT_PATH}\",\n",
                "            \"storage_server_url\": \"\",\n",
                "            \"storage_access_key\": \"\",\n",
                "            \"storage_secret_key\": \"\"\n",
                "        })\n",
                "client_config_data = infy_dpp_sdk.ClientConfigData(\n",
                "    **{\n",
                "        \"container_data\": {\n",
                "            \"container_root_path\": f\"{CONTAINER_ROOT_PATH}\",\n",
                "        }\n",
                "    })\n",
                "file_sys_handler = infy_fs_utils.provider.FileSystemHandler(\n",
                "    storage_config_data)\n",
                "if not infy_fs_utils.manager.FileSystemManager().has_fs_handler(\n",
                "    infy_dpp_sdk.common.Constants.FSH_DPP):\n",
                "    infy_fs_utils.manager.FileSystemManager().add_fs_handler(\n",
                "        file_sys_handler,\n",
                "        infy_dpp_sdk.common.Constants.FSH_DPP)\n",
                "infy_dpp_sdk.ClientConfigManager().load(client_config_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Initialize Logging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging_config_data = infy_fs_utils.data.LoggingConfigData(\n",
                "        **{\n",
                "            # \"logger_group_name\": \"my_group_1\",\n",
                "            \"logging_level\": 10,\n",
                "            \"logging_format\": \"\",\n",
                "            \"logging_timestamp_format\": \"\",\n",
                "            \"log_file_data\": {\n",
                "                \"log_file_dir_path\": \"/logs\",\n",
                "                \"log_file_name_prefix\": \"hybrid\",\n",
                "                # \"log_file_name_suffix\": \"1\",\n",
                "                \"log_file_extension\": \".log\"\n",
                "\n",
                "            }})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not infy_fs_utils.manager.FileSystemLoggingManager().has_fs_logging_handler(\n",
                "    infy_dpp_sdk.common.Constants.FSLH_DPP):\n",
                "    infy_fs_utils.manager.FileSystemLoggingManager().add_fs_logging_handler(\n",
                "            infy_fs_utils.provider.FileSystemLoggingHandler(\n",
                "                logging_config_data, file_sys_handler),\n",
                "            infy_dpp_sdk.common.Constants.FSLH_DPP)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Indexing to VectorDb & Sparse Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "INDEX_INPUT_CONFIG_FILE_PATH = '/data/config/dpp_hybrid_search_indexing_input_config.json'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show pipeline card\n",
                "PipelineHelper(INDEX_INPUT_CONFIG_FILE_PATH, STORAGE_ROOT_PATH, CONTAINER_ROOT_PATH).show_pipeline_card()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dpp_orchestrator = infy_dpp_sdk.orchestrator.OrchestratorNative(\n",
                "        input_config_file_path=INDEX_INPUT_CONFIG_FILE_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "processor_response_list = dpp_orchestrator.run_batch()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div  style=\"line-height: 1;\">\n",
                "    <span style=\"color:Green\"><b>NOTE: </b> The results of the pipeline will be available in <i>processor_response_data.json</i> file at <i>work_folder_path</i>.</span></div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Output of indexing pipeline is available at below location: \")\n",
                "print(json.dumps(processor_response_list[0].\n",
                "                 context_data.get('request_closer'),indent=4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Hybrid Search Visualizer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Retrieval "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "HYBRID_INPUT_CONFIG_FILE_PATH = '/data/config/dpp_hybrid_search_retriever_input_config.json'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ss_visualizer = SemanticSearchVisualizer()\n",
                "\n",
                "\n",
                "def form_submit_button_clicked(_):\n",
                "    user_query = ss_visualizer.get_input_text()\n",
                "\n",
                "    ss_visualizer.set_output_text('Fetching. Please wait...')\n",
                "\n",
                "    input_config_data = json.loads(file_sys_handler.read_file(\n",
                "        HYBRID_INPUT_CONFIG_FILE_PATH))\n",
                "    input_config_data['processor_input_config']['QueryRetriever']['queries'\\\n",
                "                                                                 ][0]['question']=user_query\n",
                "    input_config_data['processor_list'][1]['enabled']=False\n",
                "    print(\"Reader is enabled:\",input_config_data['processor_list'][1]['enabled'])\n",
                "    file_sys_handler.write_file(HYBRID_INPUT_CONFIG_FILE_PATH, json.dumps(\n",
                "                                input_config_data, indent=4))\n",
                "\n",
                "    dpp_orchestrator = infy_dpp_sdk.orchestrator.OrchestratorNativeBasic(\n",
                "        input_config_file_path=HYBRID_INPUT_CONFIG_FILE_PATH)\n",
                "    processor_response_list = dpp_orchestrator.run_batch()\n",
                "\n",
                "    queries_list = processor_response_list[0].context_data.get(\n",
                "        \"query_retriever\").get(\"queries\")\n",
                "    output = \"<table style='border-collapse: collapse; width: 100%;'>\"\n",
                "    output += \"<tr><th style='border: 1px solid black; width: 5%; text-align: center;'><b>Rank</b></th><th style='border: 1px solid black; width: 23.75%; text-align: center;'><b>Vector</b></th><th style='border: 1px solid black; width: 23.75%; text-align: center;'><b>Sparse</b></th><th style='border: 1px solid black; width: 23.75%; text-align: center;'><b>RRF</b></th></tr>\"\n",
                "    max_length = 0\n",
                "    for query in queries_list:\n",
                "        top_k_matches = query['top_k_matches']\n",
                "        sparseindex_list, vectordb_list, rrf_list = [], [], []\n",
                "        for match in top_k_matches:\n",
                "            if 'sparseindex' in match:\n",
                "                sparseindex_list.extend(match['sparseindex'])\n",
                "            elif 'vectordb' in match:\n",
                "                vectordb_list.extend(match['vectordb'])\n",
                "            elif 'rrf' in match:\n",
                "                rrf_list.extend(match['rrf'])\n",
                "                \n",
                "        current_max = max(len(sparseindex_list), len(vectordb_list), len(rrf_list))\n",
                "        if current_max > max_length:\n",
                "            max_length = current_max\n",
                "            \n",
                "        rank = 1\n",
                "        for i in range(max_length):\n",
                "            row = \"<tr>\"\n",
                "            row += f\"<td style='border: 1px solid black; height: 100px; text-align: center;'>{rank}</td>\"\n",
                "            for match_list in [vectordb_list, sparseindex_list, rrf_list]:\n",
                "                if i < len(match_list):\n",
                "                    row += f\"<td style='border: 1px solid black; height: 100px;'>{generate_html_for_matches([match_list[i]])}</td>\"\n",
                "                else:\n",
                "                    row += \"<td style='border: 1px solid black; height: 100px;'></td>\"\n",
                "            row += \"</tr>\"\n",
                "            output += row\n",
                "            rank += 1\n",
                "\n",
                "    output += \"</table>\"\n",
                "    ss_visualizer.set_output_text(output)\n",
                "\n",
                "colors = [\n",
                "    \"#e32636\", \"#a4c639\", \"#5d8aa8\", \"#efdecd\", \"#ffbf00\", \n",
                "    \"#008080\", \"#008000\", \"#7fffd4\", \"#b2beb5\", \"#915c83\",\n",
                "    \"#A52A2A\", \"#FFFFF0\", \"#FFC0CB\", \"#9966cc\", \"#cd9575\",\n",
                "    \"#4682B4\", \"#FA8072\", \"#FF69B4\", \"#32CD32\", \"#DAA520\"\n",
                "]\n",
                "chunk_id_to_color = {}\n",
                "def assign_color_to_chunk_id(chunk_id):\n",
                "    if chunk_id not in chunk_id_to_color:\n",
                "        chunk_id_to_color[chunk_id] = colors[len(chunk_id_to_color) % len(colors)]\n",
                "    return chunk_id_to_color[chunk_id]\n",
                "\n",
                "def generate_html_for_matches(match_list):\n",
                "    html_output = \"\"\n",
                "    for match in match_list:\n",
                "        if 'meta_data' in match and match['meta_data'] and 'chunk_id' in match['meta_data'] and match['meta_data']['chunk_id'] != '':\n",
                "            chunk_id = match['meta_data']['chunk_id']\n",
                "            color = assign_color_to_chunk_id(chunk_id) \n",
                "        else:\n",
                "            continue \n",
                "        if 'content' in match and match['content'] != '':\n",
                "            content = match['content']\n",
                "        else:\n",
                "            continue \n",
                "        score = match['score'] if 'score' in match else 'N/A'\n",
                "\n",
                "        html_output += f\"\"\"\n",
                "        <div style='background-color: {color}; padding: 10px;'>\n",
                "            <div style='text-align: left; margin: 0; padding: 0;'><b>ChunkId:</b> {chunk_id}</div>\n",
                "            <details style='text-align: left; margin: 0; padding: 0;'>\n",
                "                <summary style='margin: 0; padding: 0;'><b>Content:</b></summary>\n",
                "                <div style='margin: 0; padding: 0;'>{content}</div>\n",
                "            </details>\n",
                "            <div style='text-align: left; margin: 0; padding: 0; white-space: nowrap;'><b>Score:</b> {score}</div>\n",
                "        </div>\n",
                "        \"\"\"\n",
                "    return html_output\n",
                "\n",
                "\n",
                "def count_tokens(text):\n",
                "    count = len(text)\n",
                "    return count\n",
                "\n",
                "\n",
                "help_html = \"\"\"\n",
                "**Sample Question(s):**   \n",
                "What is the percentage of women employees?  \n",
                "What is the operating margin?  \n",
                "What is the percentage increase in return of equity from last fiscal year?  \n",
                "What is the percent YoY growth and cc growth in revenue?    \n",
                "What did the CEO and his global leadership team learn early on?    \n",
                "What rating did infosys secure on the MSCI esg assessment?    \n",
                "<hr/>\n",
                "\"\"\"\n",
                "\n",
                "display(Markdown(help_html))\n",
                "ss_visualizer.on_form_submit_callback(form_submit_button_clicked)\n",
                "ss_visualizer.set_token_counter_fn(count_tokens)\n",
                "ss_visualizer.show_ui()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ss_visualizer_search = SemanticSearchVisualizer()\n",
                "\n",
                "\n",
                "def form_submit_button_clicked_search(_):\n",
                "    user_query = ss_visualizer_search.get_input_text()\n",
                "    vector_response, sparse_response, rrf_response = None, None, None\n",
                "\n",
                "    ss_visualizer_search.set_output_text('Fetching. Please wait...')\n",
                "\n",
                "    input_config_data = json.loads(file_sys_handler.read_file(\n",
                "        HYBRID_INPUT_CONFIG_FILE_PATH))\n",
                "    input_config_data['processor_input_config']['QueryRetriever']['queries'\\\n",
                "                                                                 ][0]['question']=user_query\n",
                "    input_config_data['processor_list'][1]['enabled']=True\n",
                "    print(\"Reader is enabled:\",input_config_data['processor_list'][1]['enabled'])\n",
                "    \n",
                "    #Vector Search\n",
                "    update_storage_configs(input_config_data,enable_vectordb=True, enable_sparse=False)\n",
                "    file_sys_handler.write_file(HYBRID_INPUT_CONFIG_FILE_PATH, json.dumps(input_config_data, indent=4))\n",
                "    dpp_orchestrator = infy_dpp_sdk.orchestrator.OrchestratorNativeBasic(input_config_file_path=HYBRID_INPUT_CONFIG_FILE_PATH)\n",
                "    processor_response_list = dpp_orchestrator.run_batch()\n",
                "    print(\"processor_response_list\",processor_response_list)\n",
                "    try:\n",
                "        vector_response = processor_response_list[0].context_data.get(\"reader\")[\"output\"][0][\"model_output\"][\"answer\"]\n",
                "    except (TypeError, KeyError):\n",
                "        vector_response = processor_response_list[0].context_data.get(\"reader\")[\"output\"][0][\"model_output\"]\n",
                "    \n",
                "    #Sparse Search    \n",
                "    update_storage_configs(input_config_data,enable_vectordb=False,enable_sparse=True)\n",
                "    file_sys_handler.write_file(HYBRID_INPUT_CONFIG_FILE_PATH, json.dumps(input_config_data, indent=4))\n",
                "    dpp_orchestrator = infy_dpp_sdk.orchestrator.OrchestratorNativeBasic(input_config_file_path=HYBRID_INPUT_CONFIG_FILE_PATH)\n",
                "    processor_response_list = dpp_orchestrator.run_batch()\n",
                "    queries_list = processor_response_list[0].context_data.get(\n",
                "    \"query_retriever\").get(\"queries\")\n",
                "    print(\"query\", queries_list)\n",
                "    try:\n",
                "        sparse_response = processor_response_list[0].context_data.get(\"reader\")[\"output\"][0][\"model_output\"][\"answer\"]\n",
                "    except (TypeError, KeyError):\n",
                "        sparse_response = processor_response_list[0].context_data.get(\"reader\")[\"output\"][0][\"model_output\"]\n",
                "    \n",
                "    #RRF Search             \n",
                "    update_storage_configs(input_config_data,enable_vectordb=True,enable_sparse=True)\n",
                "    file_sys_handler.write_file(HYBRID_INPUT_CONFIG_FILE_PATH, json.dumps(input_config_data, indent=4))\n",
                "    dpp_orchestrator = infy_dpp_sdk.orchestrator.OrchestratorNativeBasic(input_config_file_path=HYBRID_INPUT_CONFIG_FILE_PATH)\n",
                "    processor_response_list = dpp_orchestrator.run_batch()\n",
                "    try:\n",
                "        rrf_response = processor_response_list[0].context_data.get(\"reader\")[\"output\"][0][\"model_output\"][\"answer\"]\n",
                "    except (TypeError, KeyError):\n",
                "        rrf_response = processor_response_list[0].context_data.get(\"reader\")[\"output\"][0][\"model_output\"]                 \n",
                "        \n",
                "        \n",
                "    output = \"<table style='border-collapse: collapse; width: 100%;'>\"\n",
                "    output += \"<tr><th style='border: 1px solid black; width: 25%; text-align: center;'><b>Vector</b></th><th style='border: 1px solid black; width: 25%; text-align: center;'><b>Sparse</b></th><th style='border: 1px solid black; width: 25%; text-align: center;'><b>RRF</b></th></tr>\"\n",
                "    output += f\"<tr><td style='border: 1px solid black; text-align: center; vertical-align: top;'>{vector_response}</td><td style='border: 1px solid black; text-align: center; vertical-align: top;'>{sparse_response}</td><td style='border: 1px solid black; text-align: center; vertical-align: top;'>{rrf_response}</td></tr>\"\n",
                "    output += \"</table>\"\n",
                "    ss_visualizer_search.set_output_text(output)\n",
                "    \n",
                "def update_storage_configs(input_config_data,enable_vectordb,enable_sparse ):\n",
                "    for storage_key, storage_value in input_config_data['processor_input_config']['Reader']['storage'].items():\n",
                "        if storage_key == 'vectordb':\n",
                "            for e_key in storage_value:\n",
                "                storage_value[e_key]['enabled'] = enable_vectordb\n",
                "        elif storage_key == 'sparseindex':\n",
                "            for e_key in storage_value:\n",
                "                storage_value[e_key]['enabled'] = enable_sparse    \n",
                "\n",
                "def count_token_search(text):\n",
                "    # Custom token count logic to be added here. Sample below.\n",
                "    count = len(text)\n",
                "    return count\n",
                "\n",
                "\n",
                "help_html = \"\"\"\n",
                "**Sample Question(s):**   \n",
                "What is the percentage of women employees?  \n",
                "What is the operating margin?  \n",
                "What is the percentage increase in return of equity from last fiscal year?\n",
                "What is the percent YoY growth and cc growth in revenue?  \n",
                "What did the CEO and his global leadership team learn early on?  \n",
                "What rating did infosys secure on the MSCI esg assessment?  \n",
                "<hr/>\n",
                "\"\"\"\n",
                "\n",
                "display(Markdown(help_html))\n",
                "ss_visualizer_search.on_form_submit_callback(form_submit_button_clicked_search)\n",
                "ss_visualizer_search.set_token_counter_fn(count_token_search)\n",
                "ss_visualizer_search.show_ui()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}