{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cfd98-8dfe-4a85-9142-44e0b5f1b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================#\n",
    "# Copyright 2023 Infosys Ltd.                                                                                    #\n",
    "# Use of this source code is governed by Apache License Version 2.0 that can be found in the LICENSE file or at  #\n",
    "# http://www.apache.org/licenses/                                                                                #\n",
    "# ===============================================================================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8989d2-a0b6-4005-a596-04db7f7da67d",
   "metadata": {},
   "source": [
    "## 1 . Installation Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2cefb-34b5-4863-a3f8-a8b2b7692b8b",
   "metadata": {},
   "source": [
    "##### Install required libraries for the document preprocessing (python >3.8.3)\n",
    "\n",
    "> `Libs:`    \n",
    "    `pip install ./lib/infy_dpp_sdk-0.0.5-py3-none-any.whl`\n",
    "    \n",
    "   > `pip install ./lib/infy_dpp_core-0.0.1-py3-none-any.whl`\n",
    "    \n",
    "   > `pip install ./lib/infy_dpp_segmentation-0.0.1-py3-none-any.whl`\n",
    "   \n",
    "- ##### `infy_dpp_core` consists of RequestCreator, metadata_extractor, document_data_saver, request_closer , document_data_updater\n",
    "- ##### `infy_dpp_segmentation` consists of segment_generator, segment_parser, chunk_generator, chunk_saver\n",
    "- ##### `infy_dpp_sdk` library is used as a dpp framework to create uniform input/output structure\n",
    "\n",
    "If you want to install all dependancies of segmentation, please install as followed.\n",
    "\n",
    "   > `pip install ./lib/infy_dpp_segmentation-0.0.1-py3-none-any.whl['all']`\n",
    "\n",
    "If you want to install for any specific library like segment-generator and segment-parser please follow below respectively\n",
    "   > `pip install ./lib/infy_dpp_segmentation-0.0.1-py3-none-any.whl['segment-generator']`\n",
    "   \n",
    "   > Download and install `pip install ./lib/detectron2-0.5+cpu-cp38-cp38-linux_x86_64.whl` from https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.9/index.html (It's supported only in linux environment.)\n",
    "   \n",
    "   > `pip install ./lib/infy_dpp_segmentation-0.0.1-py3-none-any.whl['segment-parser']`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64cf21-fc7c-42f0-b63d-adba23bea753",
   "metadata": {},
   "source": [
    "## 2. Processor Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a614fc2-5808-403e-a37f-0236a8b8d499",
   "metadata": {},
   "source": [
    "##### Please make sure to configure the `pipeline_input_config.json`.\n",
    "> 1.`RequestCreator` - `read_path` is the relative path from where processor fetches the input docs.\n",
    "\n",
    "> 2.`RequestCloser` - `output_root_path` is the relative path where processor generates the output.\n",
    "\n",
    "> 3.`SegmentGenerator` - \n",
    "\n",
    "   > `a.` Make sure textproviders properties are configured properly. Its used for extracting text from input documents.\n",
    "   \n",
    "   > `b.` To detect the segment using detectron download the model from - configure model path and config file path accordingly. (This works only in linux env)\n",
    "   \n",
    "   > github-link - https://github.com/ibm-aur-nlp/PubLayNet/tree/master/pre-trained-models\n",
    "   \n",
    "   > model-path - https://dax-cdn.cdn.appdomain.cloud/dax-publaynet/1.0.0/pre-trained-models/Mask-RCNN/model_final.pkl\n",
    "   \n",
    "   > config-path - https://github.com/ibm-aur-nlp/PubLayNet/blob/master/pre-trained-models/Mask-RCNN/e2e_mask_rcnn_X-101-64x4d-FPN_1x.yaml\n",
    "   \n",
    "   > `c.` Activate the techniques based on the file type, text providers and model providers \n",
    "   \n",
    "> `4.Segment Parser` - Provide layout and enable the pattern.\n",
    "\n",
    "> `5.ChunkDataParser` - Provide type of chunk like `page`, `paragraph`. Also you can limit pages using `page_num` property.\n",
    "\n",
    "> `6.SaveChunkDataParser` - provide the root path to save the chunks and its meta data in text file format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1b35e-8478-4a67-8e2e-d0587174b4ec",
   "metadata": {},
   "source": [
    "## 2a. RequestCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004613ee-1be0-49e1-90e1-b3b78baeb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"read_path\": \"/input/\",\n",
    "    \"batch_size\": 20,\n",
    "    \"filter\": {\n",
    "        \"include\": [\n",
    "            \"jpg\",\n",
    "            \"json\"\n",
    "        ],\n",
    "        \"exclude\": [\n",
    "            \"_\"\n",
    "        ]\n",
    "    },\n",
    "    \"work_root_path\": \"/work/\",\n",
    "    \"queue\": {\n",
    "        \"enabled\": true,\n",
    "        \"queue_root_path\": \"/work/queue/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff223425-7506-4e2b-9ef3-5351626a1e4c",
   "metadata": {},
   "source": [
    "##### `read_path`: its the relative path from where processor fetches documents\n",
    "##### `batch_size`: Here we can define how many files can be taken at a time for processing\n",
    "##### `filter`: we can mention which documents need to include and exclude.\n",
    "##### `work_root_path`: where all the internal files will be there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb3aca0-3ad5-4366-b093-23bb48c356fc",
   "metadata": {},
   "source": [
    "## 2b. RequestCloser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295d960-46c8-4b85-86fe-a7df265c3942",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"queue\": {\n",
    "        \"enabled\": true,\n",
    "        \"queue_root_path\": \"/work/queue/\"\n",
    "    },\n",
    "    \"work_root_path\": \"/work/\",\n",
    "    \"output_root_path\": \"/output/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2fab4-8945-4183-a318-674ce50dd134",
   "metadata": {},
   "source": [
    "##### `work_root_path`: This path should be same as `ReuestCreator`\n",
    "##### `output_root_path`: Output root path should be defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb83a9-cc85-4996-86d5-3433543c1be8",
   "metadata": {},
   "source": [
    "## 2c. SegmentGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c379ce-3e17-49ae-9df1-23d5e91a26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"textProviders\": [\n",
    "        {\n",
    "            \"provider_name\": \"tesseract_ocr_provider\",\n",
    "            \"properties\": {\n",
    "                \"tesseract_path\": \"\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"provider_name\": \"azure_read_ocr_provider\",\n",
    "            \"properties\": {\n",
    "                \"subscription_key\": \"\",\n",
    "                \"url\": \"\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"provider_name\": \"pdf_box_text_provider\",\n",
    "            \"properties\": {}\n",
    "        },\n",
    "        {\n",
    "            \"provider_name\": \"json_provider\",\n",
    "            \"properties\": {\n",
    "                \"template1_file_path\": \"/data/config/templates/email_template.txt\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"modelProviders\": [\n",
    "        {\n",
    "            \"provider_name\": \"detectron\",\n",
    "            \"properties\": {\n",
    "                \"model_path\": \"\",\n",
    "                \"config_file_path\": \"\",\n",
    "                \"model_threshold\": 0.8\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"techniques\": [\n",
    "        {\n",
    "            \"enabled\": false,\n",
    "            \"name\": \"technique1\",\n",
    "            \"input_file_type\": \"image\",\n",
    "            \"text_provider_name\": \"tesseract_ocr_provider\",\n",
    "            \"model_provider_name\": \"detectron\"\n",
    "        },\n",
    "        {\n",
    "            \"enabled\": false,\n",
    "            \"name\": \"technique2\",\n",
    "            \"input_file_type\": \"image\",\n",
    "            \"text_provider_name\": \"azure_read_ocr_provider\",\n",
    "            \"model_provider_name\": \"detectron\"\n",
    "        },\n",
    "        {\n",
    "            \"enabled\": false,\n",
    "            \"name\": \"technique3\",\n",
    "            \"input_file_type\": \"pdf\",\n",
    "            \"text_provider_name\": \"pdf_box_text_provider\",\n",
    "            \"model_provider_name\": null\n",
    "        },\n",
    "        {\n",
    "            \"enabled\": false,\n",
    "            \"name\": \"technique4\",\n",
    "            \"input_file_type\": \"pdf\",\n",
    "            \"text_provider_name\": \"pdf_box_text_provider\",\n",
    "            \"model_provider_name\": \"detectron\"\n",
    "        },\n",
    "        {\n",
    "            \"enabled\": false,\n",
    "            \"name\": \"technique5\",\n",
    "            \"input_file_type\": \"json\",\n",
    "            \"text_provider_name\": \"json_provider\",\n",
    "            \"model_provider_name\": null\n",
    "        },\n",
    "        {\n",
    "            \"enabled\": true,\n",
    "            \"name\": \"technique6\",\n",
    "            \"input_file_type\": \"image\",\n",
    "            \"text_provider_name\": \"azure_read_ocr_provider\",\n",
    "            \"model_provider_name\": null\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a2d42-5146-4e73-a6b3-e2d724bc131e",
   "metadata": {},
   "source": [
    "##### `textProviders`: Here provide the supported text providers and their properties\n",
    "##### `modelProviders`: Need to provide model details in list if used\n",
    "##### `techniques`: Need to enable which combination of text providers and model providers to used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f5249-c94d-40d1-8779-e1f3814af502",
   "metadata": {},
   "source": [
    "## 2d. SegmentDataParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c75987-0d6a-4622-8da6-f6804f70bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"layout\": {\n",
    "        \"single-column\": {\n",
    "            \"enabled\": true\n",
    "        },\n",
    "        \"multi-column\": {\n",
    "            \"enabled\": false\n",
    "        }\n",
    "    },\n",
    "    \"pattern\": {\n",
    "        \"sequence-order\": {\n",
    "            \"enabled\": true\n",
    "        },\n",
    "        \"left-right\": {\n",
    "            \"enabled\": false\n",
    "        },\n",
    "        \"zig-zag\": {\n",
    "            \"enabled\": false\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d830b69-07cb-4885-a9c9-339e374baf7a",
   "metadata": {},
   "source": [
    "##### `layout`: Here need to mention document column type\n",
    "##### `pattern`: Its the reading techniue from documents like top to bottom, left to right or zig zag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb5052-9ba8-4e8b-8631-6af8eb991ad2",
   "metadata": {},
   "source": [
    "## 2e. ChunkDataParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a75096-22b3-4413-a2c5-0d22353455e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"chunking_method\": \"page\",\n",
    "    \"merge_title_paragraph\": false,\n",
    "    \"page_num\": [\n",
    "        \"1:10\"\n",
    "    ],\n",
    "    \"exclude\": [\n",
    "        \"table\",\n",
    "        \"figure\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0017f16-61d1-4718-9830-1e8ea26be97e",
   "metadata": {},
   "source": [
    "##### `chunking_method`: Chunk will be paragraph or page level\n",
    "##### `page_num`: Mention the to be extracted Page number\n",
    "##### `exclude`: Need to mention which type of content type you need to exclude. Note: it works only with `detectron` model provider as of now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27950fa0-4167-481f-9434-84a34df4d254",
   "metadata": {},
   "source": [
    "## 2f. SaveChunkDataParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf187bd-9b1d-4f3f-81d3-c3692af89a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"chunked_files_root_path\": \"/vectordb/chunked\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb247791-4af7-449a-adad-8cfda39b5873",
   "metadata": {},
   "source": [
    "##### `chunked_files_root_path`: Mention where you want to save chunked data and its repective metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24fbe2-fe92-48dc-980f-0e98c00ec6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
